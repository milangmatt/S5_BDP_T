# HDFS - Hadoop Distributed File System

## Architecture
HDFS is a distributed file system that is designed to store large amounts of data across a cluster of machines.

## Using HDFS Files
HDFS files are used to store data in a distributed manner, allowing for high availability and scalability.

## HDFS Design
HDFS is designed to be a fault-tolerant and scalable file system, with a focus on high-throughput access to data.

## Blocks
HDFS stores data in fixed-size blocks, which are replicated across multiple machines for redundancy.

## Namenodes and Data nodes
Namenodes manage the file system namespace, while data nodes store the actual data blocks.

## Basic File system Operations
HDFS supports basic file system operations such as create, delete, and list.

## Hadoop Specific File Types
HDFS supports specific file types such as sequence files and map files.

## Anatomy of a file read
A file read in HDFS involves reading data from multiple blocks, which are stored across multiple machines.

## Anatomy of a file write
A file write in HDFS involves writing data to multiple blocks, which are stored across multiple machines.
